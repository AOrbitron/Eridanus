llm:
  model: gemini #选择使用的模型(这里是大类别，具体模型在底下填)，用什么配什么
  system: "你现在是一只猫娘"
  enable_proxy: False
  max_history_length: 100 #最大聊天记录条数
  openai:
    api_keys:
    - YOUR_API_KEY_1
    - YOUR_API_KEY_2
    model: glm-4-flash
    quest_url: https://open.bigmodel.cn/api/paas/v4/chat/completions #完成调用地址。只填base_url不行
  gemini:
    api_keys:
      - YOUR_API_KEY_1
    model: gemini-2.0-flash-exp
    base_url: https://inspiring-piroshki-716f76.netlify.app #后面的/v1/beta什么的会自动填充
proxy:
  http_proxy: ""
  socks_proxy: ""
